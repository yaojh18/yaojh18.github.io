---
title:          "MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation"
date:           2025-5-22 00:00:00 +0000
selected:       true
pub_post:       'Under review.'

abstract: >-
 MMMG is a comprehensive and reliable benchmark designed to evaluate multimodal generation across four modality combinations, emphasizing tasks that are hard to generate but easy to evaluate automatically. It covers 49 tasks with 937 instructions and achieves 94.3% agreement with human judgment. Evaluation of 24 models reveals persistent weaknesses in interleaved and audio generation.
cover:          /assets/images/covers/mmmg.png
authors:
  - Jihan Yao*
  - Yushi Hu*
  - Yujie Yi
  - Bin Han
  - Shangbin Feng
  - Guang Yang
  - Bingbing Wen
  - Ranjay Krishna
  - Lucy Lu Wang
  - Yulia Tsvetkov
  - Noah A. Smith
  - Banghua Zhu
links:
  Paper: https://arxiv.org/pdf/2505.17613v1
  Code: https://github.com/yaojh18/MMMG
---