---
title:          "Developing a framework for auditing large language models using human-in-the-loop"
pub_post:       'Under review.'
date:           2024-02-14 00:00:00 +0000
selected:       false

abstract: >-
 A scalable method to audit LLMs for issues like bias and inconsistencies using a secondary LLM with human-in-the-loop verification, ensuring transparent and generalizable probing.
cover:          /assets/images/covers/auditllm.png
authors:
  - Maryam Amirizaniani
  - Jihan Yao
  - Adrian Lavergne
  - Elizabeth Snell Okada
  - Aman Chadha
  - Tanya Roosta
  - Chirag Shah
links:
  Paper: https://arxiv.org/abs/2402.09346
---
